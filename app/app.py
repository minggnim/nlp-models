"""
To run Llama2 chat UI on CPU
1. Install the latest nlp_models package `pip install -U nlp_models`
2. Download `llama-2-7b-chat.ggmlv3.q8_0.bin` from https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/tree/main and place it under `models` folder
3. Run `streamlit run app.py` to spin up the UI
"""


import streamlit as st
from langchain.memory import ConversationBufferWindowMemory
from nlp_models.llm.base import LlmConfig
from nlp_models.llm.llms import build_llm
from nlp_models.llm.apps import ChatLlmApp


st.set_page_config(page_title='ğŸ¤– Llama2 chatbot on CPU', layout='wide', page_icon='ğŸ¤–')


if 'input' not in st.session_state:
    st.session_state['input'] = ''
if 'temp' not in st.session_state:
    st.session_state['temp'] = ''
if 'past' not in st.session_state:
    st.session_state['past'] = []
if 'generated' not in st.session_state:
    st.session_state['generated'] = []
if 'stored_session' not in st.session_state:
    st.session_state['stored_session'] = []


def clear_input():
    st.session_state.temp = st.session_state.input
    st.session_state.input = ""


def get_user_input():
    """
    Get the user input text.

    Returns:
        (str): The text entered by the user
    """
    input_text = st.text_input(
        "You: ",
        st.session_state["input"],
        key="input",
        placeholder="Ask me anything ...",
        on_change=clear_input,
        label_visibility='hidden'
    )
    input_text = st.session_state.temp
    return input_text


def new_chat():
    """
    Clears session state and starts a new chat.
    """
    save = []
    for i in range(len(st.session_state['generated'])-1, -1, -1):
        save.append("User:" + st.session_state["past"][i])
        save.append("Bot:" + st.session_state["generated"][i])        
    st.session_state["stored_session"].append(save)
    st.session_state["generated"] = []
    st.session_state["past"] = []
    st.session_state["input"] = ''
    st.session_state['temp'] = ''
    st.session_state.memory = ConversationBufferWindowMemory()


with st.sidebar:
    st.markdown("---")
    st.markdown("# About")
    st.markdown("ğŸ¦™ Llama2 ğŸ¤– Chatbot on CPU")
    st.markdown("The whole internet is within 8G of your laptop's memory")
    st.markdown("How cool is that!")
    st.markdown("---")


# Set up the Streamlit app layout
st.title("ğŸ¦™ Llama2 ğŸ¤– Chatbot on CPU")
st.subheader(" Powered by ğŸ¦™ Llama2 + ğŸ¦œ LangChain + Streamlit")


if 'memory' not in st.session_state:
    st.session_state.memory = ConversationBufferWindowMemory()

cfg = LlmConfig()
llm_chat_app = ChatLlmApp(llm=build_llm(cfg), memory=st.session_state.memory)

st.sidebar.button("New Chat", on_click=new_chat, type='primary')

user_input = get_user_input()

if user_input:
    output = llm_chat_app(user_input)
    st.session_state.past.append(user_input)
    st.session_state.generated.append(output)

download_str = []
# Display the conversation history using an expander, and allow the user to download it
with st.expander("Conversation", expanded=True):
    for i in range(len(st.session_state['generated'])-1, -1, -1):
        st.info(st.session_state["past"][i], icon="ğŸ§")
        st.success(st.session_state["generated"][i], icon="ğŸ¤–")
        download_str.append(st.session_state["past"][i])
        download_str.append(st.session_state["generated"][i])

    download_str = '\n'.join(download_str)

    if download_str:
        st.download_button('Download', download_str)

# Display stored conversation sessions in the sidebar
for i, sublist in enumerate(st.session_state.stored_session):
    with st.sidebar.expander(label=f"Conversation-Session:{i}"):
        st.write(sublist)

# Allow the user to clear all stored conversation sessions
if st.sidebar.checkbox("Clear-all"):
    if st.session_state.stored_session:
        st.session_state.stored_session = []
